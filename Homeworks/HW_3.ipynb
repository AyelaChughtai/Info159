{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of HW_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlFS_v7TpRHe"
      },
      "source": [
        "# Homework 3: Pytorch and CNNs\n",
        "\n",
        "In this homework, you will begin exploring Pytorch, a neural network library that will be used throughout the remainder of the semester.  This homework will focus on Convolutional Neural Networks.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyY0yl1Jpf2o"
      },
      "source": [
        "import sys, argparse\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import nltk\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "\n",
        "#Sets random seeds for reproducibility\n",
        "seed=159259\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7DVjxeq_-OF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83c6eb05-dd15-454a-8868-97c4d1f47060"
      },
      "source": [
        "!python -m nltk.downloader punkt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/runpy.py:125: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlYfHZwlQXA_"
      },
      "source": [
        "When looking up pytorch documentation, it may be useful to know which version of torch you are running.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUdEHON5lybF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b27ca1a3-11b8-4611-c817-ab61fb269330"
      },
      "source": [
        "print(torch.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.7.0+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xrbyc1flKp_"
      },
      "source": [
        "# **IMPORTANT**: GPU is not enabled by default\n",
        "\n",
        "You must switch runtime environments if your output of the next block of code has an error saying \"ValueError: Expected a cuda device, but got: cpu\"\n",
        "\n",
        "Go to Runtime > Change runtime type > Hardware accelerator > GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRy4VWrvkCP6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3866357e-af4b-46f7-b788-22a991e298f7"
      },
      "source": [
        "device = torch.cuda.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Running on {}\".format(device))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on <torch.cuda.device object at 0x7fe47db72d68>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyARzkPKmUlR"
      },
      "source": [
        "# Data Processing\n",
        "\n",
        "Let's begin by loading our datasets and the 50-dimensional GLoVE word embeddings.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_ZZQsGwH5vj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da6b5967-c485-44f2-9172-a214d3e4ac3b"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/dbamman/nlp21/main/HW3/acl.train\n",
        "!wget https://raw.githubusercontent.com/dbamman/nlp21/main/HW3/acl.dev\n",
        "!wget https://raw.githubusercontent.com/dbamman/nlp21/main/HW3/glove.6B.50d.50K.txt"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-10 21:05:43--  https://raw.githubusercontent.com/dbamman/nlp21/main/HW3/acl.train\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1027009 (1003K) [text/plain]\n",
            "Saving to: ‘acl.train’\n",
            "\n",
            "\racl.train             0%[                    ]       0  --.-KB/s               \racl.train           100%[===================>]   1003K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2021-02-10 21:05:43 (42.5 MB/s) - ‘acl.train’ saved [1027009/1027009]\n",
            "\n",
            "--2021-02-10 21:05:43--  https://raw.githubusercontent.com/dbamman/nlp21/main/HW3/acl.dev\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 359826 (351K) [text/plain]\n",
            "Saving to: ‘acl.dev’\n",
            "\n",
            "acl.dev             100%[===================>] 351.39K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2021-02-10 21:05:43 (28.9 MB/s) - ‘acl.dev’ saved [359826/359826]\n",
            "\n",
            "--2021-02-10 21:05:43--  https://raw.githubusercontent.com/dbamman/nlp21/main/HW3/glove.6B.50d.50K.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 21357789 (20M) [text/plain]\n",
            "Saving to: ‘glove.6B.50d.50K.txt’\n",
            "\n",
            "glove.6B.50d.50K.tx 100%[===================>]  20.37M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-02-10 21:05:43 (171 MB/s) - ‘glove.6B.50d.50K.txt’ saved [21357789/21357789]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vC5tWWn2mWhH"
      },
      "source": [
        "trainingFile = \"acl.train\"\n",
        "devFile = \"acl.dev\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_vLcPzzIxDw"
      },
      "source": [
        "labels = {'APPLICATIONS': 11,\n",
        " 'CSSCA': 23,\n",
        " 'DIALOGUE': 12,\n",
        " 'DISCOURSE': 13,\n",
        " 'ETHICS': 8,\n",
        " 'GENERATION': 9,\n",
        " 'GREEN': 15,\n",
        " 'GROUNDING': 18,\n",
        " 'IE': 6,\n",
        " 'INTERPRET': 10,\n",
        " 'IR': 22,\n",
        " 'LEXSEM': 7,\n",
        " 'LING': 24,\n",
        " 'MLCLASS': 1,\n",
        " 'MLLM': 16,\n",
        " 'MT': 4,\n",
        " 'MULTILING': 3,\n",
        " 'OTHER': 25,\n",
        " 'PHON': 5,\n",
        " 'QA': 17,\n",
        " 'RESOURCES': 14,\n",
        " 'SA': 21,\n",
        " 'SENTSEM': 0,\n",
        " 'SPEECH': 19,\n",
        " 'SUMM': 2,\n",
        " 'SYNTAX': 20}"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNb4H1auI4lA"
      },
      "source": [
        "def get_batches(x, y, xType, batch_size=12):\n",
        "    batches_x=[]\n",
        "    batches_y=[]\n",
        "    for i in range(0, len(x), batch_size):\n",
        "        batches_x.append(xType(x[i:i+batch_size]))\n",
        "        batches_y.append(torch.LongTensor(y[i:i+batch_size]))\n",
        "    \n",
        "    return batches_x, batches_y\n",
        "        "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnIbufFHlYSx"
      },
      "source": [
        "PAD_INDEX = 0             # reserved for padding words\n",
        "UNKNOWN_INDEX = 1         # reserved for unknown words\n",
        "SEP_INDEX = 2\n",
        "\n",
        "data_lens = []\n",
        "\n",
        "def read_embeddings(filename, vocab_size=50000):\n",
        "  \"\"\"\n",
        "  Utility function, loads in the `vocab_size` most common embeddings from `filename`\n",
        "  \n",
        "  Arguments:\n",
        "  - filename:     path to file\n",
        "                  automatically infers correct embedding dimension from filename\n",
        "  - vocab_size:   maximum number of embeddings to load\n",
        "\n",
        "  Returns \n",
        "  - embeddings:   torch.FloatTensor matrix of size (vocab_size x word_embedding_dim)\n",
        "  - vocab:        dictionary mapping word (str) to index (int) in embedding matrix\n",
        "  \"\"\"\n",
        "\n",
        "  # get the embedding size from the first embedding\n",
        "  with open(filename, encoding=\"utf-8\") as file:\n",
        "    word_embedding_dim = len(file.readline().split(\" \")) - 1\n",
        "\n",
        "  vocab = {}\n",
        "\n",
        "  embeddings = np.zeros((vocab_size, word_embedding_dim))\n",
        "  with open(filename, encoding=\"utf-8\") as file:\n",
        "    for idx, line in enumerate(file):\n",
        "\n",
        "      if idx + 2 >= vocab_size:\n",
        "        break\n",
        "\n",
        "      cols = line.rstrip().split(\" \")\n",
        "      val = np.array(cols[1:])\n",
        "      word = cols[0]\n",
        "      embeddings[idx + 2] = val\n",
        "      vocab[word] = idx + 2\n",
        "  \n",
        "  # a FloatTensor is a multidimensional matrix\n",
        "  # that contains 32-bit floats in every entry\n",
        "  # https://pytorch.org/docs/stable/tensors.html\n",
        "  return torch.FloatTensor(embeddings), vocab\n",
        "\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrBHMiLPIOKB"
      },
      "source": [
        "# Logistic regression\n",
        "\n",
        "First, let's code up logistic regression in pytorch so you can see how the general framework works, and also get a sense of baseline performance that we can compare a CNN against."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7A8N5GNJH4x8"
      },
      "source": [
        "def get_vocab(filename, max_words=10000):\n",
        "    unigram_counts=Counter()\n",
        "    with open(filename) as file:    \n",
        "        for line in file:\n",
        "            cols=line.rstrip().split(\"\\t\")\n",
        "            idd = cols[0]\n",
        "            label = cols[1]\n",
        "            title = cols[2]\n",
        "            abstract = cols[3]\n",
        "            strr=\"%s %s\" % (title, abstract)\n",
        "            words=nltk.word_tokenize(strr)\n",
        "\n",
        "            for word in words:\n",
        "                word=word.lower()\n",
        "                unigram_counts[word]+=1\n",
        "\n",
        "    vocab={}\n",
        "    for k,v in unigram_counts.most_common(max_words):\n",
        "        vocab[k]=len(vocab)\n",
        "    return vocab\n",
        "        "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "392D8YLfI_K3"
      },
      "source": [
        "class LogisticRegressionClassifier(nn.Module):\n",
        "\n",
        "   def __init__(self, input_dim, output_dim):\n",
        "      super().__init__()\n",
        "      self.linear = torch.nn.Linear(input_dim, output_dim)\n",
        " \n",
        "    \n",
        "   def forward(self, input): \n",
        "      x1 = self.linear(input)\n",
        "      return x1\n",
        "\n",
        "   def evaluate(self, x, y):\n",
        "\n",
        "      self.eval()\n",
        "      corr = 0.\n",
        "      total = 0.\n",
        "      with torch.no_grad():\n",
        "        for x, y in zip(x, y):\n",
        "          y_preds=self.forward(x)\n",
        "          for idx, y_pred in enumerate(y_preds):\n",
        "              prediction=torch.argmax(y_pred)\n",
        "              if prediction == y[idx]:\n",
        "                corr += 1.\n",
        "              total+=1                          \n",
        "      return corr/total\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgaDKtOrc10l"
      },
      "source": [
        "## Average Embedding Representation\n",
        "Let's train a logistic regression classifier where the input is the average GLoVE embedding for all words in a paper's title and abstract"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YgU4027luO3"
      },
      "source": [
        "def read_glove_data(filename, vocab, embs):\n",
        "    data=[]\n",
        "    data_labels=[]\n",
        "    with open(filename) as file:\n",
        "        for line in file:\n",
        "            avg_emb=np.zeros(50)\n",
        "            cols=line.rstrip().split(\"\\t\")\n",
        "            idd = cols[0]\n",
        "            label = cols[1]\n",
        "            title = cols[2]\n",
        "            abstract = cols[3]\n",
        "            strr=\"%s %s\" % (title, abstract)\n",
        "            words=nltk.word_tokenize(strr)\n",
        "            avg_counter = 0.\n",
        "            for word in words:\n",
        "                word=word.lower()\n",
        "                if word in glove_vocab:\n",
        "                    avg_emb += embs[glove_vocab[word]].numpy()\n",
        "                    avg_counter += 1.\n",
        "            avg_emb /= avg_counter\n",
        "\n",
        "            data.append(avg_emb)\n",
        "            data_labels.append(labels[label])\n",
        "    return data, data_labels "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYb1iVsqb0Le"
      },
      "source": [
        "embs, glove_vocab = read_embeddings(\"glove.6B.50d.50K.txt\")\n",
        "avg_train_x, avg_train_y=read_glove_data(trainingFile, glove_vocab, embs)\n",
        "avg_dev_x, avg_dev_y=read_glove_data(devFile, glove_vocab, embs)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FeYYf7-c01Z"
      },
      "source": [
        "avg_trainX, avg_trainY=get_batches(avg_train_x, avg_train_y, xType=torch.FloatTensor)\n",
        "avg_devX, avg_devY=get_batches(avg_dev_x, avg_dev_y, xType=torch.FloatTensor)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Duzn0vCrdR5X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "482fbfaa-89b4-4234-dfe2-a7e08298ddf6"
      },
      "source": [
        "logreg=LogisticRegressionClassifier(50, len(labels))\n",
        "optimizer = torch.optim.Adam(logreg.parameters(), lr=0.001, weight_decay=1e-5)\n",
        "losses = []\n",
        "cross_entropy=nn.CrossEntropyLoss()\n",
        "\n",
        "num_labels=len(labels)\n",
        "\n",
        "for epoch in range(200):\n",
        "    logreg.train()\n",
        "    \n",
        "    for x, y in zip(avg_trainX, avg_trainY):\n",
        "        y_pred=logreg.forward(x)\n",
        "        loss = cross_entropy(y_pred.view(-1, num_labels), y.view(-1))\n",
        "        losses.append(loss)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    dev_accuracy=logreg.evaluate(avg_devX, avg_devY)\n",
        "    if epoch % 5 == 0:\n",
        "        print(\"Epoch %s, dev accuracy: %.3f\" % (epoch, dev_accuracy))\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0, dev accuracy: 0.080\n",
            "Epoch 5, dev accuracy: 0.097\n",
            "Epoch 10, dev accuracy: 0.140\n",
            "Epoch 15, dev accuracy: 0.177\n",
            "Epoch 20, dev accuracy: 0.200\n",
            "Epoch 25, dev accuracy: 0.206\n",
            "Epoch 30, dev accuracy: 0.220\n",
            "Epoch 35, dev accuracy: 0.229\n",
            "Epoch 40, dev accuracy: 0.231\n",
            "Epoch 45, dev accuracy: 0.237\n",
            "Epoch 50, dev accuracy: 0.240\n",
            "Epoch 55, dev accuracy: 0.246\n",
            "Epoch 60, dev accuracy: 0.251\n",
            "Epoch 65, dev accuracy: 0.260\n",
            "Epoch 70, dev accuracy: 0.266\n",
            "Epoch 75, dev accuracy: 0.263\n",
            "Epoch 80, dev accuracy: 0.266\n",
            "Epoch 85, dev accuracy: 0.266\n",
            "Epoch 90, dev accuracy: 0.266\n",
            "Epoch 95, dev accuracy: 0.266\n",
            "Epoch 100, dev accuracy: 0.263\n",
            "Epoch 105, dev accuracy: 0.263\n",
            "Epoch 110, dev accuracy: 0.269\n",
            "Epoch 115, dev accuracy: 0.271\n",
            "Epoch 120, dev accuracy: 0.274\n",
            "Epoch 125, dev accuracy: 0.277\n",
            "Epoch 130, dev accuracy: 0.277\n",
            "Epoch 135, dev accuracy: 0.277\n",
            "Epoch 140, dev accuracy: 0.289\n",
            "Epoch 145, dev accuracy: 0.297\n",
            "Epoch 150, dev accuracy: 0.303\n",
            "Epoch 155, dev accuracy: 0.306\n",
            "Epoch 160, dev accuracy: 0.314\n",
            "Epoch 165, dev accuracy: 0.317\n",
            "Epoch 170, dev accuracy: 0.320\n",
            "Epoch 175, dev accuracy: 0.320\n",
            "Epoch 180, dev accuracy: 0.326\n",
            "Epoch 185, dev accuracy: 0.326\n",
            "Epoch 190, dev accuracy: 0.326\n",
            "Epoch 195, dev accuracy: 0.320\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObjO1BiXc_nY"
      },
      "source": [
        "## BOW Representation\n",
        "Feel free to fill in your bag-of-words implementation into read_bow_data() to see how the logistic classifier model works with a different featurization.  (You are not required to do anything within this BOW representation section; we provide the structure in case you'd like to explore how your your BOW logistic regression model from the last homework could be implemented in Pytorch)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huWSY2FNlqrF"
      },
      "source": [
        "def read_bow_data(filename, vocab):\n",
        "    data=[]\n",
        "    data_labels=[]\n",
        "    with open(filename) as file:\n",
        "        for line in file:\n",
        "            cols=line.rstrip().split(\"\\t\")\n",
        "            idd = cols[0]\n",
        "            label = cols[1]\n",
        "            title = cols[2]\n",
        "            abstract = cols[3]\n",
        "            strr=\"%s %s\" % (title, abstract)\n",
        "            bow=np.zeros(len(vocab))\n",
        "\n",
        "            '''\n",
        "            Insert your bow code here to store the featurization in the bow variable \n",
        "            \n",
        "            '''\n",
        "\n",
        "            data.append(bow)\n",
        "\n",
        "            data_labels.append(labels[label])\n",
        "    return data, data_labels \n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tc9ZGJvWImkA"
      },
      "source": [
        "bow_vocab=get_vocab(trainingFile)\n",
        "bow_train_x, bow_train_y=read_bow_data(trainingFile, bow_vocab)\n",
        "bow_dev_x, bow_dev_y=read_bow_data(devFile, bow_vocab)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFucMsZII8Hb"
      },
      "source": [
        "bow_trainX, bow_trainY=get_batches(bow_train_x, bow_train_y, xType=torch.FloatTensor)\n",
        "bow_devX, bow_devY=get_batches(bow_dev_x, bow_dev_y, xType=torch.FloatTensor)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byr4SJB1JCDO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dcc6089-ba25-482e-d710-1109d43fbbba"
      },
      "source": [
        "logreg=LogisticRegressionClassifier(len(bow_vocab), len(labels))\n",
        "optimizer = torch.optim.Adam(logreg.parameters(), lr=0.001, weight_decay=1e-5)\n",
        "losses = []\n",
        "cross_entropy=nn.CrossEntropyLoss()\n",
        "\n",
        "num_labels=len(labels)\n",
        "\n",
        "for epoch in range(200):\n",
        "    for x, y in zip(bow_trainX, bow_trainY):\n",
        "        y_pred=logreg.forward(x)\n",
        "        loss = cross_entropy(y_pred.view(-1, num_labels), y.view(-1))\n",
        "        losses.append(loss)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    dev_accuracy=logreg.evaluate(bow_devX, bow_devY)\n",
        "    if epoch % 5 == 0:\n",
        "        print(\"Epoch %s, dev accuracy: %.3f\" % (epoch, dev_accuracy))\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0, dev accuracy: 0.086\n",
            "Epoch 5, dev accuracy: 0.086\n",
            "Epoch 10, dev accuracy: 0.086\n",
            "Epoch 15, dev accuracy: 0.086\n",
            "Epoch 20, dev accuracy: 0.086\n",
            "Epoch 25, dev accuracy: 0.086\n",
            "Epoch 30, dev accuracy: 0.086\n",
            "Epoch 35, dev accuracy: 0.086\n",
            "Epoch 40, dev accuracy: 0.086\n",
            "Epoch 45, dev accuracy: 0.086\n",
            "Epoch 50, dev accuracy: 0.086\n",
            "Epoch 55, dev accuracy: 0.086\n",
            "Epoch 60, dev accuracy: 0.086\n",
            "Epoch 65, dev accuracy: 0.086\n",
            "Epoch 70, dev accuracy: 0.086\n",
            "Epoch 75, dev accuracy: 0.086\n",
            "Epoch 80, dev accuracy: 0.086\n",
            "Epoch 85, dev accuracy: 0.086\n",
            "Epoch 90, dev accuracy: 0.086\n",
            "Epoch 95, dev accuracy: 0.086\n",
            "Epoch 100, dev accuracy: 0.086\n",
            "Epoch 105, dev accuracy: 0.086\n",
            "Epoch 110, dev accuracy: 0.086\n",
            "Epoch 115, dev accuracy: 0.086\n",
            "Epoch 120, dev accuracy: 0.086\n",
            "Epoch 125, dev accuracy: 0.086\n",
            "Epoch 130, dev accuracy: 0.086\n",
            "Epoch 135, dev accuracy: 0.086\n",
            "Epoch 140, dev accuracy: 0.086\n",
            "Epoch 145, dev accuracy: 0.086\n",
            "Epoch 150, dev accuracy: 0.086\n",
            "Epoch 155, dev accuracy: 0.086\n",
            "Epoch 160, dev accuracy: 0.086\n",
            "Epoch 165, dev accuracy: 0.086\n",
            "Epoch 170, dev accuracy: 0.086\n",
            "Epoch 175, dev accuracy: 0.086\n",
            "Epoch 180, dev accuracy: 0.086\n",
            "Epoch 185, dev accuracy: 0.086\n",
            "Epoch 190, dev accuracy: 0.086\n",
            "Epoch 195, dev accuracy: 0.086\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbHrmE4jJQrT"
      },
      "source": [
        "# Deliverable 1. CNN \n",
        "\n",
        "Now let's create our CNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YhST7BOJPoG"
      },
      "source": [
        "def read_data(filename, vocab, labels):\n",
        "    \"\"\"\n",
        "    :param filename: the name of the file\n",
        "    :return: list of tuple ([word index list], label)\n",
        "    as input for the forward and backward function\n",
        "    \"\"\"    \n",
        "    data = []\n",
        "    data_labels = []\n",
        "    file = open(filename)\n",
        "    for line in file:\n",
        "        cols = line.split(\"\\t\")\n",
        "        idd = cols[0]\n",
        "        label = cols[1]\n",
        "        title = cols[2]\n",
        "        abstract = cols[3]\n",
        "        w_int = []\n",
        "        for w in nltk.word_tokenize(title.lower()):\n",
        "            if w in vocab:\n",
        "                w_int.append(vocab[w])\n",
        "            else:\n",
        "                w_int.append(UNKNOWN_INDEX)\n",
        "        w_int.append(SEP_INDEX)\n",
        "        w_int.append(SEP_INDEX)\n",
        "        for w in nltk.word_tokenize(abstract.lower()):\n",
        "            if w in vocab:\n",
        "                w_int.append(vocab[w])\n",
        "            else:\n",
        "                w_int.append(UNKNOWN_INDEX)\n",
        "        data_lens.append(len(w_int))\n",
        "        if len(w_int) < 549:\n",
        "            w_int.extend([PAD_INDEX] * (549 - len(w_int)))\n",
        "        if len(w_int) < 550:\n",
        "          data.append((w_int))\n",
        "          data_labels.append(labels[label])\n",
        "    file.close()\n",
        "    return data, data_labels"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sB60ratJZvB"
      },
      "source": [
        "embs, cnn_vocab = read_embeddings(\"glove.6B.50d.50K.txt\")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hStl2tmiJesV"
      },
      "source": [
        "cnn_train_x, cnn_train_y = read_data(trainingFile, cnn_vocab, labels)\n",
        "cnn_dev_x, cnn_dev_y = read_data(devFile, cnn_vocab, labels)\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZNvT-REJgv1"
      },
      "source": [
        "cnn_trainX, cnn_trainY=get_batches(cnn_train_x, cnn_train_y, torch.LongTensor)\n",
        "cnn_devX, cnn_devY=get_batches(cnn_dev_x, cnn_dev_y, torch.LongTensor)\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNnwNSPbGxYb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "496ab4ac-dd1f-4a0b-fbe2-1032e9e2981a"
      },
      "source": [
        "len(embs[0])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDGz8mqdJjic"
      },
      "source": [
        "class CNNClassifier(nn.Module):\n",
        "\n",
        "   def __init__(self, params, pretrained_embeddings):\n",
        "      super().__init__()\n",
        "      self.seq_len = params[\"max_seq_len\"]\n",
        "      self.num_labels = params[\"label_length\"]\n",
        "      \n",
        "      '''\n",
        "      Initialize the following layers according to the hw spec\n",
        "      '''\n",
        "      self.embeddings = nn.Embedding.from_pretrained(\n",
        "          torch.FloatTensor(pretrained_embeddings))\n",
        "\n",
        "      # convolution over 1 word\n",
        "\n",
        "      # Each of these layers should be a nn.Conv1d layer with 50 filters which \n",
        "      # convolves over the glove embeddings. self.conv 1 should have a 1-word window, \n",
        "      # self.conv 2 should have a 2-word window, and self.conv 3 should have a 3-word \n",
        "      # window. All should have a stride of 1\n",
        "\n",
        "      # (in_channels: int, out_channels: int, kernel_size: Union[T, Tuple[T]], \n",
        "      #  stride: Union[T, Tuple[T]] = 1, padding: Union[T, Tuple[T]] = 0, dilation: \n",
        "      #  Union[T, Tuple[T]] = \n",
        "      #  1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros')\n",
        "\n",
        "      # self.pool 1, self.pool 2, self.pool 3: These should be the nn.M axP \n",
        "      # ool1d layers corresponding to self.conv 1, self.conv 2, and self.conv 3.\n",
        "\n",
        "      self.conv_1 = nn.Conv1d(in_channels = 50, out_channels= 50,\n",
        "                              kernel_size = 1, stride = 1)\n",
        "      self.pool_1 = nn.MaxPool1d(kernel_size = 549)\n",
        "\n",
        "      # convolution over 2 words    \n",
        "      self.conv_2 = nn.Conv1d(in_channels = 50, out_channels= 50,\n",
        "                              kernel_size = 2, stride = 1)\n",
        "      self.pool_2 = nn.MaxPool1d(kernel_size = 548)\n",
        "        \n",
        "      # convolution over 3 words\n",
        "      self.conv_3 = nn.Conv1d(in_channels = 50, out_channels= 50,\n",
        "                              kernel_size = 3, stride = 1)\n",
        "      self.pool_3 = nn.MaxPool1d(kernel_size = 547)\n",
        "        \n",
        "      # self.fc: This should be a linear layer which takes in the concatenated \n",
        "      # 1-, 2-, and 3-word CNN representations and outputs a prediction over the \n",
        "      # topic category classes.\n",
        "\n",
        "      self.fc = nn.Linear(150, self.num_labels)\n",
        "\n",
        "\n",
        "    \n",
        "   def forward(self, input): \n",
        "      #embeds the input sequences\n",
        "      x0 = self.embeddings(input)\n",
        "      #changes dimensions to be consistent with conv1d\n",
        "      x0 = x0.permute(0, 2, 1)\n",
        "\n",
        "      '''\n",
        "      Create the hidden representations according to the hw spec\n",
        "      '''\n",
        "      #Apply the one-word convolution, tanh, and pool\n",
        "      x1 = self.pool_1(torch.tanh(self.conv_1(x0)))\n",
        "    \n",
        "      #Apply the two-word convolution, tanh, and pool\n",
        "      x2 = self.pool_2(torch.tanh(self.conv_2(x0)))\n",
        "        \n",
        "      #Apply the three-word convolution, tanh, and pool\n",
        "      x3 = self.pool_3(torch.tanh(self.conv_3(x0)))\n",
        "\n",
        "      #Concatenates the output of all 3 convolution layers\n",
        "      combined=torch.cat((x1,x2,x3), 1).squeeze()\n",
        "\n",
        "      #Connects the combined output to the fully-connected layer\n",
        "      out = self.fc(combined)\n",
        "      return out.squeeze()\n",
        "\n",
        "   def evaluate(self, x, y):\n",
        "      \n",
        "      self.eval()\n",
        "      corr = 0.\n",
        "      total = 0.\n",
        "\n",
        "      with torch.no_grad():\n",
        "\n",
        "        for x, y in zip(x, y):\n",
        "          y_preds=self.forward(x)\n",
        "          for idx, y_pred in enumerate(y_preds):\n",
        "              prediction=torch.argmax(y_pred)\n",
        "              if prediction == y[idx]:\n",
        "                corr += 1.\n",
        "              total+=1                          \n",
        "      return corr/total\n",
        "\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxrBo0N0JlGM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65c44f72-d050-4c4f-c986-6d284282aaa9"
      },
      "source": [
        "embs, cnn_vocab = read_embeddings(\"glove.6B.50d.50K.txt\")\n",
        "cnnmodel = CNNClassifier(params={\"max_seq_len\": 549, \"label_length\": len(labels)}, pretrained_embeddings=embs)\n",
        "optimizer = torch.optim.Adam(cnnmodel.parameters(), lr=0.001, weight_decay=1e-5)\n",
        "losses = []\n",
        "cross_entropy=nn.CrossEntropyLoss()\n",
        "\n",
        "num_epochs=25\n",
        "best_dev_acc = 0.\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    cnnmodel.train()\n",
        "\n",
        "    for x, y in zip(cnn_trainX, cnn_trainY):\n",
        "      y_pred = cnnmodel.forward(x)\n",
        "      loss = cross_entropy(y_pred.view(-1, cnnmodel.num_labels), y.view(-1))\n",
        "      losses.append(loss) \n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    dev_accuracy=cnnmodel.evaluate(cnn_devX, cnn_devY)\n",
        "    if epoch % 1 == 0:\n",
        "        print(\"Epoch %s, dev accuracy: %.3f\" % (epoch, dev_accuracy))\n",
        "        if dev_accuracy > best_dev_acc:\n",
        "          torch.save(cnnmodel.state_dict(), 'best-cnnmodel-parameters.pt')\n",
        "          best_dev_acc = dev_accuracy\n",
        "\n",
        "cnnmodel.load_state_dict(torch.load('best-cnnmodel-parameters.pt'))\n",
        "print(\"\\nBest Performing Model achieves dev accuracy of : %.3f\" % (best_dev_acc))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0, dev accuracy: 0.120\n",
            "Epoch 1, dev accuracy: 0.183\n",
            "Epoch 2, dev accuracy: 0.294\n",
            "Epoch 3, dev accuracy: 0.334\n",
            "Epoch 4, dev accuracy: 0.366\n",
            "Epoch 5, dev accuracy: 0.386\n",
            "Epoch 6, dev accuracy: 0.409\n",
            "Epoch 7, dev accuracy: 0.411\n",
            "Epoch 8, dev accuracy: 0.417\n",
            "Epoch 9, dev accuracy: 0.411\n",
            "Epoch 10, dev accuracy: 0.417\n",
            "Epoch 11, dev accuracy: 0.429\n",
            "Epoch 12, dev accuracy: 0.429\n",
            "Epoch 13, dev accuracy: 0.423\n",
            "Epoch 14, dev accuracy: 0.437\n",
            "Epoch 15, dev accuracy: 0.440\n",
            "Epoch 16, dev accuracy: 0.431\n",
            "Epoch 17, dev accuracy: 0.434\n",
            "Epoch 18, dev accuracy: 0.437\n",
            "Epoch 19, dev accuracy: 0.454\n",
            "Epoch 20, dev accuracy: 0.449\n",
            "Epoch 21, dev accuracy: 0.449\n",
            "Epoch 22, dev accuracy: 0.451\n",
            "Epoch 23, dev accuracy: 0.449\n",
            "Epoch 24, dev accuracy: 0.451\n",
            "\n",
            "Best Performing Model achieves dev accuracy of : 0.454\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8j5kM7T5T69d"
      },
      "source": [
        "# Model Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7u2MerXT9fb"
      },
      "source": [
        "## Loss Examination\n",
        "To debug your model and ensure it is updating correctly, it may be helpful to visualize your training loss.  The following code plots loss over epoch.  This should decrease as the model trains and eventually converge.  If your training loss is not decreasing, you might not be initializing your model or creating your forward() pass correctly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0W1WDYkfrdLX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "7dbecc7d-6dbb-4aca-9e36-8d301296ce43"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(range(len(losses)), losses)\n",
        "plt.title(\"Training Loss over Time\")\n",
        "plt.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd5hU1fnA8e+7ld6XXpYmCIoISxWwC4LRJCb2EqMhGo0maiLqL2qsxCTGYInB3isWIlgAUUAFXHqV3ttSl7aw5fz+mDuzM7NT7sxOvft+nmcf7tx75s6Zy+47Z957ihhjUEoplf4ykl0BpZRSsaEBXSmlHEIDulJKOYQGdKWUcggN6Eop5RAa0JVSyiE0oKuYEJHPROTaWJdV0RORK0Xky2TXQyWOaD/0mktEDnk9rAMcA8qtx781xryZ+FpFT0TOAN4wxrRNdl0SQUTuAe6xHmYB2cBR6/FGY0zPpFRMJY220GswY0w99w+wCfiJ1z5PMBeRrOTVUrn5/z8YYx71+v+7Efje6/9Pg3kNpAFdVSEiZ4jIFhG5S0R2AC+LSGMR+VREikRkn7Xd1us5X4vIDdb2r0Rkloj8wyq7XkTOj7JsRxGZISIHRWSqiDwjIm9E8Z5OtF53v4gsE5ELvY6NFJHl1mtsFZE7rf3NrPe5X0T2ishMEQn4NyMig0XkBxE5YP072Np/qYgU+pX9o4hMtLZzrfe+SUR2ishzIlI72P9DhO/5VyIyy+uxEZHfichq670+JCKdReQ7ESkWkfdEJMer/AUistB6/9+JSK9IXl8lngZ0FUxLoAnQARiN63flZetxe1xf7Z8O8fwBwI9AM+Bx4EURkSjKvgXMBZoCDwBXR/pGRCQb+B/wJdAc+D3wpoh0s4q8iCvFVB84CfjK2n8HsAXIA1rgSm9UyVGKSBNgEjDOqucTwCQRaWq9bjcR6er1lCus9wUwFjgB6A10AdoA93mV9f9/qK7hQF9gIPBnYDxwFdAO13u/3HpPpwIvAb+13tN/gYkikhuDOqg40YCugqkA7jfGHDPGHDXG7DHGTDDGHDHGHAQeAU4P8fyNxpjnjTHlwKtAK1xB0XZZEWkP9APuM8YcN8bMAiZG8V4GAvWAsdZ5vgI+xQpeQCnQQ0QaGGP2GWPme+1vBXQwxpQaY2aawDedRgGrjTGvG2PKjDFvAytxpbCOAJ9QGSi7At1xBUfBFaT/aIzZa13XR4HLvM7t8/8QxXv397gxptgYswxYCnxpjFlnjDkAfAacapUbDfzXGDPHGFNujHkV1z2WgTGog4oTDegqmCJjTIn7gYjUEZH/ishGESkGZgCNRCQzyPN3uDesoAauoBpJ2dbAXq99AJsjfB9Y59lsjKnw2rcRV2sY4GJgJLBRRL4RkUHW/r8Da4AvRWSdiIwJcf6Nfvu8z/8WlR8eVwAfW+8pD9fN6HlWWmM/8Lm1383n/yEGdnptHw3w2P1/1AG4w10vq27tcL1XlaI0oKtg/FuidwDdgAHGmAbAMGt/sDRKLGwHmohIHa997aI4zzagnV/+uz2wFcAY84Mx5iJc6ZiPgfes/QeNMXcYYzoBFwK3i8jZQc7fwW+f5/zAFCBPRHrjCuzudMtuXEG0pzGmkfXT0LrJ6ZasbmibgUe86tXIGFPH+vahUpQGdGVXfVzBZ7+VM74/3i9ojNkIFAIPiEiO1XL+SbjniUgt7x9cOfgjwJ9FJFtc3Rt/ArxjnfdKEWlojCkFinGlOdw3BbtYqZEDuLp0VgR4ycnACSJyhYhkicilQA9caR2s876Pq8XfBFeAx/rG8DzwLxFpbr1mGxEZHs31irHngRtFZIC41BWRUSJSP9kVU8FpQFd2PQnUxtWqnI0rNZAIVwKDgD3Aw8C7uHK5wbTB9cHj/dMOVwA/H1f9nwWuMcastJ5zNbDBSiXdaL0mQFdgKnAI+B541hgz3f8FjTF7gAtwfYvZg+tm4wXGmN1exd4CzgHeN8aUee2/C1daZ7b1+lNxfRNKKmNMIfAbXDe+9+Gq46+SWScVng4sUmlFRN4FVhpj4v4NQal0oy10ldJEpJ/VVzpDREYAF+HKcyul/OgIQJXqWgIf4uoLvQW4yRizILlVUio1acpFKaUcQlMuSinlEElLuTRr1szk5+cn6+WVUiotzZs3b7cxJi/QsaQF9Pz8fAoLC8MXVEop5SEi/qOSPTTlopRSDqEBXSmlHEIDulJKOYQGdKWUcggN6Eop5RAa0JVSyiE0oCullEM4JqB/snArB0tKk10NpZRKGkcE9GXbDnDbOwsZ8+ESdG4apVRN5YiAfvR4OQCTFm+n492T2XEglkswKqVUeggb0K1lvOaKyCIRWSYifw1Q5lciUiQiC62fG+JT3cD82+Trdx9O5MsrpVRKsDOXyzHgLGPMIRHJBmaJyGfGmNl+5d41xtwS+ypGTuK5bLFSSqWosAHduJLSh6yH2dZPSieqMzSiK6VqIFs5dBHJFJGFwC5gijFmToBiF4vIYhH5QETaBTnPaBEpFJHCoqKialTbl/99UI3nSqmayFZAN8aUG2N6A22B/iJykl+R/wH5xphewBTg1SDnGW+MKTDGFOTlBZzONybsxPNrX5rLO3M3xa0OSimVaBH1cjHG7AemAyP89u8xxhyzHr4A9I1N9QJ794dNdL13MqXlFUDVFrnYaKJ/s6qIMR8uIX/MJL5fuyce1VRKqYSy08slT0QaWdu1gXOBlX5lWnk9vBBYEctK+rtrwhJKyw3/nrqaJ6asqnI80pTLxwu2xqhmSimVPHZ6ubQCXhWRTFwfAO8ZYz4VkQeBQmPMROBWEbkQKAP2Ar+KV4W9PT19DQBDujTz2R/pTdEMR/TGV0rVdHZ6uSwGTg2w/z6v7buBu2NbtegFC+f3fLSEt+ZsYsPYUb7l9S6qUsoB0q5terysImyZd37YzOIt+6vsf2tO4JugGRrPlVIOkHYB/X+LtoUt8/bcTVz49Le2z6n91pVSTpB2Ab2krLzKvgNHA8+y+MnCreSPmcTmvUdCnjNYQN9ZXMIDE5dRVl7BzW/N5+a35nPr2wu0V4xSKiXZuSmaUsorqg5S/c1rhQHL3vbOQgC+XbOby/q39+yv8DtHsAb63R8u4auVuzize3MmLd7u2f/5sh2sevj8SKuulFJxlXYt9EABPRx3f3W3Mr9zBGuhu8tVGP/yEVdBKaXiroYEdOP32DfABwvQnv3Gf79GdKVU6km7gN6jVYOIn/PBvC0+C19UDeiBA7R7r38LXcO5UioVpV1A75RXL+LnLN9eTMe7J3seH/cL6B/M28K7P1Tt0ujun+4/+VeoFvqs1bspKw/ftVIppWIt7QJ6LPLXU5bv9Hm85/Bx7pqwhCemrGLUuJks3XoAqGyJ+yd5gsXzWat3c9WLczwjWJVSKpHSL6DHIKLf+9HSgPvHTVvNsm3FPDLJNRWNO3D7r1MabGRp0SHX0ncbdMUkpVQSpF23xWb1cjmpTQOWbi2O22tU3ni1Ui5+x8N9phhg457DrNt9mNnr9tC+SR2uHNAh1tVUSikfaRfQAUYP68ytby+I2/mLS0qZubrIE7jt5tCFypz7Gf/42ud5GtCVUvGWdimXRFi54yBXvziXdVbqZOv+oz7Hg6VcPCkaqn4IKKVUvGlAD+FgiWtKgYc+Xe6z3zue/2/RNopLAk89oJRSiZSWAd3/JmWiFR08xofzt7Bxz2F+//YCbrPSP5XdHO3X7x9f/OjpVaOUUtWRlgE9Fdz+3iJPznzVzkNA8G6OwRhjeHr6Gn7y9KzYV1ApVeNoQA9hZ/GxkMeH/X06UDXH/t2a3bbO7+5Mo/l2pVQsaECPIXdufd+R4Dn1jxdsZfk2V5dL/ykFlFKqOjSgx8jo1wrZfTB0ix7gD+8uZOS4mYC2zJVSsRW2H7qI1AJmALlW+Q+MMff7lckFXgP6AnuAS40xG2JeW4v/otCp4MvlO5m/qeqyd6FoC10pFUt2WujHgLOMMacAvYERIjLQr8z1wD5jTBfgX8DfYltNX03r5TL3nrPj+RIJ4R3PN+w+zJgJi3n40+Vc8fzs5FVKKZW2wrbQjasP3iHrYbb149+0vAh4wNr+AHhaRMTEsX9hg9rZ8Tp11HYfCp5y2bD7MPnN6vrsM16X8Yx/fB2vaimlaghbOXQRyRSRhcAuYIoxZo5fkTbAZgBjTBlwAGga4DyjRaRQRAqLioqqVfHszPRK/7umAvD9fItirQ5W7ihm057Qa6QqpWomW1HRGFNujOkNtAX6i8hJ0byYMWa8MabAGFOQl5cXzSk8MjOEDWNHce2g9JkjpfhomWe7pLTcVg79xVnree6btZ7HI56c6ekuqZRS3iJq5hpj9gPTgRF+h7YC7QBEJAtoiOvmaNxlhWipj+rVKhFVsM17igARe71cHvp0OWM/WxnHWimlnCJsQBeRPBFpZG3XBs4F/CPMROBaa/sXwFfxzJ/71C/I/g1jR/HMFX0SUQXbbvGaIdKY5E9hoJRyFjst9FbAdBFZDPyAK4f+qYg8KCIXWmVeBJqKyBrgdmBMfKobuVTq4rhoc2W3xkmLt0eVQ1dKqWDs9HJZDJwaYP99XtslwC9jWzV7wsXEN24YQP6YSQmpSyTueH8Rz13VN9nVUEo5SHp1FbHhN0M78sb1A5JdDVtufGNe0GOPTl4RcrHpwY9NY9y01fGollIqTaV9QL+4T1sAmtbNAWB4z5YM6Zo6aZZojZ+xjuk/VnbtPF7mG9y3HSjhiSmrEl0tpVQKS/uA3qN1AzaMHUWHpnUA38Un/HXKq8tfLugR8FhulutSvDvafxBs8pR6tdA/Xrg1YJnPl+7wefz23E1c8tz3ca2XUio1peWaooHYub94Wb92QW+SLrjvXIyBurmpc0nKvO+aBnmD7rTNqofPJycrg7s/XJKAmimlUlHat9DdGllTAQQaQfrmDa6c+uDOzYIO5qmTk5VSwRygwiugZ2SE+OqBb2ve261vL6DvQ1NiWi+lVGpKrQhWDf+8pDcfL9jKyW0aVjl2WpdmrH9sJCLC4WNlZGUIgzo3ZeZqewtRJEu5V0APN9NBRpBc08RF22JZJaVUCnNMC71J3Rx+PaSjZ11Pf+79dXOzWPPoSM7r0QKAc3u04NPfD0lYPSORlVn5Xuau3xuyrLG98J1SyqkcE9Aj5Q5/LRrkcpJfq/7FawsSX6EASssrg/TbczeHLDtn3V6fFr1SquapsQH9p6e24cxuefz+rK5Vjp3Qor7t8zx1eZUxVzFz5/uLbJe97pUf+HeIfumz1+1hzrqETK+jlEqSGhvQG9TK5uXr+tOiQa0qx9w3GBvUyuK7MWeFPM9Z3ZvHpX6BjLKWrgtm1Y6Dnm3/hasvGz+bS8frwhlKOVmNDeihuFMXPVs3pHWj2iHL1s3NomfrBomoFsusxaWD8c6j3/HeQlvnPHC0lDfnbNSJwpRyAMf0comlLs3rcd8FPbiod+ugZZ69sg9b9rkWmqiXIt0do0mh3/3hYiYv2UGPVg04tX3j2FdKKZUw2kIPQET49ZCONK2XG7TMyW0aMnpYZwDGXtwrUVULyU4j+805G30e7z50HIBjZcHnjVFKpQcN6FGqlZ3p2e7ot1Zo8oSP6GMnr2TGqqLKFItmWpRyDA3oNrxx/QBPX/XMDGHCTYPJqx+89Z4s3imXvYePByxz8FgZ17w0lynLdyaoVkqpRNGAbsOQrs1ob03+VSc7k74dUj/XvGrnoZDHx321mrVFVcvMWFXEJc99r33alUpDqXE3Lw3Uz83isn7tuKRfu2RXJahgw/8DWbq1mJ88NYuTWrsGVbmfees7C9h/pJTio6U0tqYkVkqlBw3oNolIytz8DCbM/F1VHDle7tn2b49r+1yp9GNnkeh2IjJdRJaLyDIRuS1AmTNE5ICILLR+7gt0LhVfX1YjL75xz2Gfxw/+bxld7plc3SoppRLITg69DLjDGNMDGAjcLCKBVomYaYzpbf08GNNappFUmQcG4Iy/T7dd9q4JvvOof7xwm+987BZjDF8u2xFyeTylVHKEDejGmO3GmPnW9kFgBdAm3hVLNz/t3Zpbz+rC2Se2CFnutV/3T1CNYMOeIxE/J1zWZuqKXYx+fR7/+XptdJVSSsVNRDl0EckHTgXmBDg8SEQWAduAO40xywI8fzQwGqB9+/aR1jWlPXmZvUm6IrhvmZJ2HzoGVJ0rRimVfLa7LYpIPWAC8AdjjP+kIvOBDsaYU4CngI8DncMYM94YU2CMKcjLy4u2zmmtWYjRp6no5W/XJ7sKSimbbAV0EcnGFczfNMZ86H/cGFNsjDlkbU8GskUk8OKdNdRNZ3Rmwk2DOLFVAy7vn7pdH/399X/LAddyeMYYW9MLKKWSw04vFwFeBFYYY54IUqalVQ4R6W+dVyff9pKdmUHfDk0AeOznqdP90c5KR3sPH+eE//uM4U/O8OxL99SRUk5kJ4d+GnA1sERE3HOy3gO0BzDGPAf8ArhJRMqAo8BlpgbPx9o/vwmHj5f5THfbpE52EmsUnJ0BoX2sRabDjT5VSiVX2IBujJlFmM4PxpingadjVal0996NgwDIHzMJgLE/P5lfFqRmmmXexn2e7Rr8GayUI+hcLglwWf/2ZEY6jDMJoonn+48c5473FlF08BhfrdQJv5RKJh36H0ef/2Eo9WulZqolkApjkDDJcXfO/e25m3ns570YN20NE+ZvYcL8LQBMvX0YXZrbX5NVKRU72kKPo+4tG9AmzBJ2qeRYWUW1Z1k8WFLm87iiwnDRM9/yxbId1TqvUio8DejKo+f9X3DgaGm1zuH/cXC8vIJFm/dz69sLqnVepVR4mnJRMeX+QCgpLedYaQU5WdpmUCpR9K8tycZf3TfZVYiI943TQOmZ617+AYALnprFKQ9+6dmv/daVij8N6El2Xs+Wya5C1LaFmM9lzS7fPuvaI1Kp+NOAriLi3dI+cLQ0bMvbzkhUpVRsaEBPktvPPYFebRuGLTekS2pNiXPvR0vDltmyr3LaXndWRlMuSsWfBvQkufXsrky8ZUjQ4y0a5HLLmV149qo+CaxVbAz5W+XCGjr6VKnE0V4uKSorI4M7h3dLdjWqzd1CLynVFY6UijdtoaeAEQFujGZ4/c8svO/cBNbGPluN7yBldhWXcNrYr1i/+3DgAkqpiGlATwHPXNmHFQ+O8NmX4ZV0blQnh1rZqfdfZTBhl6yrCBL1P128na37j/LqdxsAKC2v8KyCNOLJGdz+7sKAz1NKBZd6UaIGyswQaudkeh7nZmVw14juPmUyUvCu4px1e/l2behp7/3DeUlpORc9PYuFm/e7jlsB/75PlnHa2K8oLill5Y6DfLhgazyqrJSjaQ49Bf348PlV9qVeOIdHJq8IW8a7hW6MYfXOQyzacoBFWw4ArkWn/3oRTF+5C4BDfnPBKKXs04CeQsac3531RYFzyhlpMP1uIEePl3u23yvcTI9Wvl01t+4/Sml5hadbo/aJUSp6GtBTyI2ndw56LB3mUw9k6OOVXRhX7TxUJaCD6+aqO6Wk3RyVip7m0NNEVpoGdH+BbgX4pmUSWBmlHEYDeppIxZuisWJMZaDXgK5U9MIGdBFpJyLTRWS5iCwTkdsClBERGScia0RksYik3/DGFOdOuXw75iyGdk2t6QCq65XvNrBln6vLos79olT07LTQy4A7jDE9gIHAzSLSw6/M+UBX62c08J+Y1lJ5Anp5uUnbVmyw7xh/+3ylZ9t7Rl7vOWGUUuGFDejGmO3GmPnW9kFgBdDGr9hFwGvGZTbQSERaxby2NZg7h15WUeHoVqx3Pn3/keCrJy3ZcoD8MZNYuaM4EdVSKi1ElEMXkXzgVGCO36E2wGavx1uoGvQRkdEiUigihUVFRZHVtIZzt9ArTPAW+hd/GJbAGkXOzm2ACq8munf58grDOU98w+dLXWuTTl66HYBpK3bxycKt/Hvq6pjWVal0ZDugi0g9YALwB2NMVM0iY8x4Y0yBMaYgLy8vmlPUWPeOOpEmdXNo06hO0OH03VrWZ+VDI/j6zjNo0SA3wTWMjce/+NGz7d1Vs/hoKWt2HeKuCYuByvSNMYbb3lnIv6auSmQ1lUpJtgK6iGTjCuZvGmM+DFBkK9DO63Fba5+KkbO6t2D+X86ldk4mN5/ZJWi5WtmZ5Dery1ndWySwdvY8P3M9Fzw1K2SZKct3erbfmrMJgGkrdrJ+j2vAlXvN0sp+6/GoqVLpyU4vFwFeBFYYY54IUmwicI3V22UgcMAYsz2G9VRehnbNY8PYUeRkBv/vc0K39de+3wjA9a8W8vNnv/Psn71ujycdE2BZU6VqLDsjRU8DrgaWiIh7Crx7gPYAxpjngMnASGANcAS4LvZVVZFwcLd1Nu45XJlycfANYqUiFTagG2NmEWZuKOMar31zrCqlIndBL99ORZkOjugVBs8nlqZclKqkc7k4wI8PjyA3K9NnX7pO5mVHhTFeLXSllJsO/U9j5/Zw3fgM1Bp3cgv93o+W8u9prm6K3pN5lZWHXubu+7V7OHJcp+dVzqUBPY09cekpfDfmLLIC3BxN19kZI/Wfr9d6tsfPXBe03Nb9R7n8+dn86YPFiaiWUkmhAT2N5WZl0rpR7YDHnJxy8Vbm1c1l76HjQcsdPuZqmf+442Dc66RUsmhAdyh3yuWXfdsmuSaJs8Ba1i4Q74+3jxZsoeDhqZRrn0flMBrQHcrdQm9YOzvJNUmceRv3+Ty+8fV5PDXNd0oAYwz/99FSdh86xtHScpRyEg3oDuVuodfOyeThn54UsMxrv+6fyCpF5cx/fB31cz9ftoN/TlnFuqJDPkvcabtcOZUGdIfKyqyczCs7M3A+fdgJeXzxh2Gcc2LqTRPgtn534DVWQ1m27QBLtx7wPL73o6UEGkpRM+4yqJpE+6E71K8G57Nxz2F+e3pnjIH3CreQnSnMXrfXp1y3lvUZ2KkJU1fsDHKm9DNqnO98Mf6TmelgJOVU2kJ3qLq5WTz+i1NoUCubhrWzmXDTYNo3qZPsaiWFdwDftv+oJ3eucV05jQZ05XiuFrorfJeUVg4+MmGa6je+Po83Zm+MZ9WUiikN6MrxCjfu45wnZlTZH2pFJHDdVP2/j5fGq1pKxZwG9Bro8v7teGf0QM9jcfA0AaEMfXx6squgVExpQK+BTmnbiIGdmia7GmmjvMIwZfnOsCkapZJNA3oNVEMb5FH774y1/Oa1Qr5Y5pyeQMqZNKDXIKOHdaZ9kzpV+p23axx4Pph09EKICbrCWbr1AM9MX0PRwWM++1/5dgMAuw8dC/AspVKHBvQapEvzesz485k0ree7gPR5PVvyj1+eAkDbEMF9/NV941q/WHh40oqon3vBU7P4+xc/8hO/dU93HdRArtKDBnQFwMBOTQCoCDFh1antG/N/o05MVJWSZkdxSVTP233oGLuifK5SsaABXQHQqmFthvdswVNX9PHsu2ZQB58yOZkZ3DC0E7PuOjPR1YsrY0xMZl4seHgq/R+dFoMaKRWdsEP/ReQl4AJglzGmyixPInIG8Amw3tr1oTHmwVhWUsVfZobw36sLAHj8F73o2KwupeUVvPZ95cCa7CzX3VSndXO87Z2FTFy0LWw5h71t5UB2WuivACPClJlpjOlt/WgwT3OXFLSjX36TKvtzrJWRnLZ2RqBgnj9mUpV99360lIMloQcjKZVMYQO6MWYGsDdcOeV87mXtpAbPUxhudKlSyRSrHPogEVkkIp+JSM9ghURktIgUikhhUVFRjF5aJYo71VKTUw+52eH/ZJZuPcDERds4XhZ60WqlYi0WAX0+0MEYcwrwFPBxsILGmPHGmAJjTEFeXl4MXlolQkGHxiy6/zzPYycF9EhHf9r5dnLBU7O49e0FPDxpebTVUioq1Q7oxphiY8wha3sykC0izapdM5UysjLFZyk7J6Vcnv5qTUTljdeku9sPHOXTxcFvpi7bVhx1vZSKRrUDuoi0FOu7uIj0t865p7rnVemva/N6ya5CWP+csiqyJ3g16C/57/fc8tYCRjxZdSZHO1btPMh7P2yO6rlKBWKn2+LbwBlAMxHZAtwPZAMYY54DfgHcJCJlwFHgMqOzGDlCiwa1AOjbobHPfrspl6sGdqBffhN+8dx3HDnujAWZvX+xt+93DSJaueNgVOc671+uD4JL+rWrbrWUAmwEdGPM5WGOPw08HbMaqZTROa8eU28fRsdmvi1t73jeu10jFm7eD8DvzujMs1+v9RzLzBB6tG7A8gdHBOwGmI68myreH2x3f7i4Stl5G/dhjHFcv32VunSkqAqpS/P6nu6K/urkZPL+jYM8j/88orvPcXe/dScxGHYdLGHGqiKfewlvzw2cOpkwf2vYcy7fVsys1btjVkdVc+ki0SpquVkZZIcI2u6RpU5iDPR/xP7w/s17j4QtM3LcTAA2jB0Vdb2UAm2hqyjYTSFkZTjv1yvSm0MZmm5RCeS8vziVMkK13tPVnHWRdeCK5BIU67QCqpqc9xenEsbdWp3/l3OZe8/ZPsdyMjPol9+46pPS3O3vLYqofEYEE9/87JlvI62OUj40h64i5h+imtTNqVJm1SPnJ6YyKc475bJpzxGueWkO/fKb0Ktdoypl1xYdDnmuXQdLeHHWev48vHvQG9WqZtOAriJWOycTgKsGdAhTMjKZGRKTeclTiXfc/fe01WzYc4QNe47w/rwtAcvvO3ycxgE+IAHunrCEaSt3MbRLHkO66mBsVZWmXFTEamVnsvbRkdxx3gkRP3fq7cM82789vZPPsVPaNmTD2FGO6u2RIcKMVUW8/v0GWwOybnpzXtBjx8tdk33tLC7h86XbY1RD5SQa0FVUMjMkaG+XSwraBn1el+b1Pdt3Dffrt57lvF/HzAzhmpfm8pdPltmaR377gfBL2N3x/iJufGM+JaXOGH2rYkdTLiqmImld+38e5GRlxrg2yRdpt8VIylfoDBvKj/OaRCpt+LfwczKdd6Pv7bmbPNvvFQbOm3vTe52qOjSgq5TRs3XDZFch5iKduCuS3ivrwvSKUTWPBnSVEj64cRC3nt012dVIOv+55o+VlTNu2mq63ju5yjeaC56aFdR8IEwAABlqSURBVPZ8367Z7bieQyo4zaGrlFAQYFHqmmpd0SEmLtrGLwvacdrYrzz7A7XdN+05QvumdQKe59s1u7nyhTncMKQjZRWGu0d2J9eB9ylUJW2hq4S7YkB722Xr54Zuc1zWrx3PX1NQ3SqlDIPhqhfm8OTU1RRuCL82+7C/Tw96bGexq8fMC7PW88p3G/jQxsyPKr1pQFcJ98hPT2LtoyNtlV3y1+EMtQbRjL+6b5XjYy/uxbk9WsS0fskkCEet7oixHg2qvWKcT1MuKuFEhEg6tLi78mU7sJ96IO6Ud5ZfQP9mVVFE5/HvAanx3Pk0oKukeuGaAjLDRHdPYKoBAenHnZW9YjKrOf2wkxbzVvaE/Y0RkZdEZJeILA1yXERknIisEZHFItIn9tVUTnVOjxac2a15yDKV8dw3ovdq67xujt5e+W59VM/bcaCEv3y8lDLt3VLj2GkCvAKMCHH8fKCr9TMa+E/1q6VUJXd3vYqKyn2f/n4Ib9wwIEk1Soxv19ibe33NrkP0uO9zz+pI93y0hNdnb2TWat8Uzf99HLBN5uPzpTtYv/swZ//za+Zt3Bd5pVVS2VkkeoaI5IcochHwmjHGALNFpJGItDLG6OxBKiYCZVxOauPs1nkk3pm7iSPHy/ls6XZe/nZDyPlg5m/aR5/2geepr6gw3PhG5eRgj01ewQc3DY55fVX8xOIuUxvAe4XcLda+KkRktIgUikhhUVFkN3hUzeXOoRsbd/Um3DSYf116StDjPVo1oGfrBuQ66AarO7OSIRJ2cq+fP/td0GPletc07SX0t9oYM94YU2CMKcjLy0vkS6u05orodsJNx2Z1PTcDz+7enO4t6/scn3zbUCbdOpT+HZ0zkMl9b8HuWq/B+I8o1eVQ008sAvpWoJ3X47bWPqViYoAVfNs2rh22rFAZiOqGGZTkFO/94PqC7N9tfUdx+Kl4vfn3U9cGe/qJRUCfCFxj9XYZCBzQ/LmKpRuGduSbP51Bz9YNueXMLrRpFDywe7cqQ8WjHActYH34uGsgkv/Uu7PXBR9punjLfo6VuZ535HgZ17/yA5v3Ho26DuNnrGXexvAjW1V8hW3CiMjbwBlAMxHZAtwPZAMYY54DJgMjgTXAEeC6eFVWpa9/X9Y7ZCAORUTo0LQuAHcO78adw7uFLQ++Lc5Hf3YyfTtU3gzMdlBAd7ObItmy7wgXPv0tlxa042+/6MWXy3YybeWuauXQH528EohsPnwVe3Z6uVwe5rgBbo5ZjZQjXdQ74H3ymJMgw2lOadeQbn75dLd/XXoKf3x3UXwrlgD3fbLMVrn9R0oBWLL1AH//YiWfL90BVM2hF27cx/YDR2nVMPgH8fdr99Cgds1IbaUD5zVTVM0mviNLw90ofPbKPpx+QuiBTYCzbqK6e8VkwDPT17LWmlc90DS7gx77qso+b5c/P5tR48JP46sSQz9aleO42+ihJqPyjvOZXg9O69LUZ0DP3y4+mR0HjnFCi3rMXe+MHPH8Ta4BQ/4597JyvQua7rSFrhxFpLK3h3c8D5UeFq+/gqFdfbvTXtqvPbed46yFN+6f6ErN+H93KfMeihtna3YdYm3RoYS9Xk2hAV05jmcgEsbT1bF2TuCFHYzxbal6B7l6Xt0endgn2z8dNX/T/qBlRzw5g6emrfY8fmLKKpZuPRD1a5/zxDec/c9von6+CkxTLspRBGhWLxeAjs3q8bszOzNz1W4659XzLRck5eI2elgn7hl5YjyrmnQl1rzr4RhjWLnjICt3HOSmMzpTVmEYN201T321OvyTVUJpQFeOIiIU5Dfh9ev7M7BTU7IzMxjVq1XQ8gYTsPVddZoBV6HWDWsx+bah9H5wSgxrnRx2F7D2vld63Ss/MHP1biBwGuvI8TLq5AQPK0u2HIh4wJOyTwO6ciT/XLg/786N3isDBUutuPf3bNOQRnVyql2/dPLNql2ebXcwD6bHfV8w/c4z6NisbsDjP3lae8TEk+bQlaNEk+r27+0Rieeu8p3+39298fM/DI36nKnm168URlR+7a5D7D18nN2HjsWsDiWl5eyJ4fmcSlvoylEijc2um6KVj93pgmBpA/80w6l+U9E+f00B2w8cpUndmtWK95aZKfR5yJWSitXI0cufn82CTft1JGoYGtBVzeQVxL17e1zWrx2Hj5Vx7eD8YMUD7s+rn8vce85GRGhYO5uigzW3NZkdYOm8Ux/8khNaBB6pa8eCED1wVCVNuShHqe46mlmZGfz29M7Uyg7czTEY4zcq1fubwrujB1arTunG+57E1v1HeWLKKvYdKWVOgIFZFbpMXkxpQFeOEnHKxfr3ljO78OHv7KzO4xeAgt1E9doe0KlpZJVKcx/M2+LZvvnN+YybFrx7Y6d7JrN1f/BZHp/9eg35YyZFXIeKCsPew8cjfl6604CuUlKf9o3IzozfaB7/M985vFvQpdnAzuIR/otDBC7fo1UDn8cDO7luop5/Ussw508fE+ZXBvTjZeFHnz4yaTlFB48FXMP0hZnRLZT99PQ19HloCjvCrODkNJpDVynpw9+dluwq2JKb5UrNdG/pG6iDhf/Jtw31tDgXP3AeWRnCE1+u4o/nnsBn1qyHTpLpv+pGAFkZGYwaN5NdB495bnoeLCnlaGl51D2Qpq7YCbgW+WjZsFZU50hHGtBVjWZnnVLf8r6PG9bO5p3RA+nR2jeg2wlEDWplA/B/F/SIqA7pZImN6QGyMzPY5XcT+ZwnvmFn8TGa18+t1us7cMaGkDTlohzFboMu0vU3Q5Ue2KmpJzjbekIYM/98pqNWVApn1c7KEaslpeU89Olydha7ArydFn6sOCE9U3N+a1SNUN1eLnY99vOTefqKU4PXoxrVaNekTtDnt2zgvPSBdyv+zTmbeHFWZd7c/5tOn4em8O2a3RhjKC4prXKuH3ccJH/MJDbvPQLYW1gcYPa6PQx8bBr/W7Qt8jeQQjSgqxop2njrDhCX92/PBb1ax/z8blkBWqYvXlvAGzf0B+CUtg2r+QqpyT8F5r/oxt7Dx7nyhTm8/O0Gej3wpSdwu71f6Fowe9+RqsE+lOXbigEC3phNJxrQlaPEa5rbSM8bKqUzomdL/jwi9LqoGVZAn3PP2Z59Z5/Ygi7N6/PKdf147foBPuUHOaRr5MOTVvg8DrZIyefLXDeQt+xzdXncWVzCe4Wbyc6q2SHN1rsXkREi8qOIrBGRMQGO/0pEikRkofVzQ+yrqlR4kcbzaqyLHFKoejx3dV9+d0aXkM93pxoCfS6c0a05DWtX5uz75Tf2zPvuNP43SwFysjI8LfnMDOG17zcw4skZ/PmDxRwMkIaJl9nr9nDgaOJez46wAV1EMoFngPOBHsDlIhLotvy7xpje1s8LMa6nUiFF3oKO7nXs9orxP/9pXSJrQbtvBtq5J/DEJb0D3jzsl9+Yu8/vHtHrpoPjZRX8sMGVGtl/5Dj3fbLMk2LxH3j6xbIdrN4ZeprgbfuPhlyuMJBDx8q4bPxsfvt6ZBOXxZudFnp/YI0xZp0x5jjwDnBRfKulVHQi7b1i/7wRlvcLxK//egBrHx1p+/meZfRs3NZr16SOJ0Xj7e3fDOS3p3e2/ZrpyP+DrKzcdyDTf75ey7n/msHGPYfJHzOJ79b6Tv+7s7iEwWO/4h9f/hjR65ZaA6bszimfKHYCehtgs9fjLdY+fxeLyGIR+UBE2gU6kYiMFpFCESksKiqKorpKBRb9Tc745Fz8PwAyMiSiLnjulEtFBXz4u8G8fF2/kOXdqy553yx1f7gtfuA8Vj40wqf8iJ7OGJl6/au+LeSyIHPDzF7nWvj74wVbKSktp7S8guXbij0pk5LSxK2nGk+xuoPwPyDfGNMLmAK8GqiQMWa8MabAGFOQlxd6AQKlIuE/jW041e3lEm/u4F9uDH3aN+bMbs1tlb+od2Vby/0eG9TKrjLZ2DWDOgQ8T7p3i9x9KPD8LW/NdbVJM0To/pfP6XrvZ4wcN5Ovf9wVsLxdkWRqxn620tMLJ17sBPStgHeLu621z8MYs8cY47578QLQNzbVU8qel6/rxyc3nxbxQBS7f5CR9m+vzqIZAP+85BT65Temhc2Rku737Z0L9q9C/VqugeF3jegesDfIM1f0YbZXr5p0NGNV4G/+iza7pt/1T025uyu6vfLdBs76x9eAK7d+rKzquqv7jxynJMD+cJ77Zi1/+mBxxM+LhJ2A/gPQVUQ6ikgOcBkw0buAiHgv2ngh4Nv3SKk4a1Arm1PaNbJdPl659srzV+/5gzs34/0bB5Nlc8SoO6CXVRieuvxUerVtWOU9NraWzjvnxOY+Hzgnt3GladwfBnPuOZuXr+vHsBOc9y3aP4AfCzB52LrdhymvMAwe+xV/fHdhleO9H5zCBeNcS+nF+dcoYmF/W4wxZcAtwBe4AvV7xphlIvKgiFxoFbtVRJaJyCLgVuBX8aqwUslkv0WfWJ6cuzH85JTWTLxlSNCyIpUDl05u05AOTet4ngvQokEtzuzWnN5e+fhIPixT2cLNvgtlBAroAC9/6xqtOnXFLnYcKGHNrkP85rVClm1zjWrdY03NG69ur9GyNTmXMWYyMNlv331e23cDd8e2akrFn+0/SE+vE5vFE9x0G9y5Kc99szbMFMCeLZ8WvZ300H+v6svAx6b57Dv9hDyevLQ3Fz/3HeuKDkdb9aT6amXgHLp7gFOmiM/7dg9kcjtwtJQXZ63n+iEdPYt1+Kd1tuw7krDAX7OHVakaK9JwG+/y1TXshDyW/nU4A22MGBWBrEx3LxrDn4Z3Y0iXZpx9YouqBXEt/pEXIJeflSE0rpvDBzcOpqBDZDel08XRUt9ceWl51Rb9Q58uZ1dxCZ3umczPnv22yvEhf5vO0Menx62O3jSgKxWBaAcWJUK93NBfuMXr3yyvXjTtmtThjRsGBH1+pl+Xy0d/djJQmaJpUjeHD24azGe3Da3eG0gDh0rKAu6fZrX0F205wL7Dx5m7fi8TF21jxfbigOXjRedDVzVavFIoiU65RKpTs3pcM6hD0O6LUPkB4H+N3DdRT2jpu+izd+rms9uGcv6/Z1Y554axo/hy2Q5Gvz4vqnon247iwFPs3v3hEs/2VS/OYdm24IE8f8wkPv39EE5qE/sJ1rSFrmokdw+O7i2jX4k+3Xh/yGRkCA9edBJdmgd//8E+k05u25APbhzEnef5TjDmnTo+0WupvT7tfW+ontezJYvuO4/fnt4pgtqnj1DB3O37tXvi8toa0FWN9NNT27Do/vNst5JSu70dZ15pJvcaqAX5Tcj261Lp/sBw95pxm3BT1cW3G9bJ5u7zT/Q87tK8XsCXfu6qPtHVOcXVyskMXygKmnJRNZb3jIU1if2OPb4fYyseHBFy4W7P/DN+LyAi9O3QmMv6BZwRBICpt5/uWWvV2/CeLRl3+am0aVSLi//zvc2ap7462fEJ6NpCVyoCqdbvOBLV/ZZROycz5EAn//sGD//0JO4d6WqFT7hpML8sCB7Qvb15Q+Vc7yLChae0pm+HJnz6e9++9Se1aeD/VF7+Veg5b1JFbW2hK5U8KX6PMyKRfijZLe4/Q+RVA4PfcA3ltC7NGHlyyyrfoLzTY38a3o1pK3ZWee6Z3Zvz6M9OZmCnJpz1z2+iev1EqO7UEEHPG5ezKuUwTeu6+mF3S+ebqHGeM96doon2W8zEW07zzN/+7JV9eeznvYKWven0zp4c/jl+/eevGNCeTnn1mHyrbzfKUSe3wt/z1xREV9lq8l9aL1a0ha6UDT1aN+CDGwc5ZAh8ZMHE9nQH1Wx09mrbiF5t7V3fjAxhUOemzFm/lz+P6MawE5rx7Rrfuc57tK5MydTKzmBwl6ZMWrLdp0zX5vUYf3VfGtTO5uoX51BaXvlmczIzOB5gIFEslFXE57zaQlfKpkA9O9KJp195hPPRRDpnfKLuM9x6Vlem/HEYJ7SozzWD8vnv1cFb21/8YZjPwCn3Ddo6uZmc17MlAzs1Zelfh9PT60Ng9LCq3SrvOPeEmNRdW+hKqWqJfHBUnCoSIxkZQtcW9lJgTevlMurkVqzaeZDRQztTOyeTG4Z2onn9yvnfc7MyPTNS1snJ5JazuvD09DXWsQyOlVVQWl7BlD8OY2fxMUTgsc9WsHSrq995vdwsDh0LPJLUX7CFOKorfZsbSqWBa0OMxEyWSENJolIu8ZQhkJWZwZ+Gd6dhnWxysjIC9n2vle0Kif+6tDe1sjP5zdCOPHdVX76/+2zO7t6cawfn07VFfYZ0bcZpXZrx22GVS/x9cstpVc7XrkltXry2gE7N6vLG9QM8i3lrC12pNLNh7KhkV8FHxBOMRRmh7c53k0j2FyjxLXfvqB6e7RcDdIl0X6LTujSlc149fnZqG5ZuPcB/rurDI5NWcMtZXejboYln4rOPfnca/R6ZGrcWugZ0pWqYeHVbTOX5a+xWTYIMjgpa3voAcHex/NelvT3HXr6uf5XynknR4nSzVQO6Uinimz+dEbf+yRB9SiReHwCJZPe6VpaKbFZNu51WMjMr56GPB82hK5UiOjStS7smdcIXtHQNMv9JOHZ7rUTeD906fwpGdLtLzUbeQrfK27ymWRnxDejaQlcqTX1882m2e1UADOjYlFU7D9Godk5ErxOvD4BEspsO8gyOivC8dj8AsjJcbWi9KaqU8lE3N4u6YRa18PaXC3pw7eAOtGxYK3xhoK+1nN3AjuFXQfIWab/1RLDbQrfibcQ9e+zGZ08LvTyJKRcRGSEiP4rIGhEZE+B4roi8ax2fIyL5sa6oUqp6XF317E9dMKBTUxY/cB5ndm9uq3xevVz65TfmiUt6hy+cYJG20Cvsrkzl2bJXPiNDEIHyOI0UDfvxLiKZwDPAucAW4AcRmWiMWe5V7HpgnzGmi4hcBvwNuDQeFVZKJU6DWvanGM7KzOD9G6vOfR7Kp78fQuO69lNAj1/ci92Hj9kuf8WA9rw1Z5Pt8ie2qs+kJdtpZfNbTH3r+gRaczWYrAyJWw5dwvUZFZFBwAPGmOHW47sBjDGPeZX5wirzvYhkATuAPBPi5AUFBaawsDAGb0EppQKrqDCUG2N7yobyCsOiLfvp097eotfGGD6Yt4VRvVpRJ8de+uvWtxdwVvfm/PTUNrbK+xORecaYgPMc2KlBG2Cz1+MtwIBgZYwxZSJyAGgK+MyWIyKjgdEA7du3t1V5pZSKVkaGkBHBkKrMDLEdzMGVyrE7z7vbuMtPjah8JBLabdEYM94YU2CMKcjLy0vkSyullOPZCehbAe+PoLbWvoBlrJRLQyA+q6AqpZQKyE5A/wHoKiIdRSQHuAyY6FdmInCttf0L4KtQ+XOllFKxFzaHbuXEbwG+ADKBl4wxy0TkQaDQGDMReBF4XUTWAHtxBX2llFIJZOu2rDFmMjDZb999XtslwC9jWzWllFKR0LlclFLKITSgK6WUQ2hAV0ophwg7UjRuLyxSBGyM8unN8Bu0pKrQaxSaXp/w9BqFlqzr08EYE3AgT9ICenWISGGwoa/KRa9RaHp9wtNrFFoqXh9NuSillENoQFdKKYdI14A+PtkVSAN6jULT6xOeXqPQUu76pGUOXSmlVFXp2kJXSinlRwO6Uko5RNoF9HDrm9YUIrJBRJaIyEIRKbT2NRGRKSKy2vq3sbVfRGScdc0Wi0if5NY+PkTkJRHZJSJLvfZFfE1E5Fqr/GoRuTbQa6WjINfnARHZav0eLRSRkV7H7rauz48iMtxrv2P/BkWknYhMF5HlIrJMRG6z9qfH75ExJm1+cM32uBboBOQAi4Aeya5Xkq7FBqCZ377HgTHW9hjgb9b2SOAzXGvaDgTmJLv+cbomw4A+wNJorwnQBFhn/dvY2m6c7PcWx+vzAHBngLI9rL+vXKCj9XeX6fS/QaAV0Mfarg+ssq5FWvwepVsLvT+wxhizzhhzHHgHuCjJdUolFwGvWtuvAj/12v+acZkNNBKRVsmoYDwZY2bgmr7ZW6TXZDgwxRiz1xizD5gCjIh/7eMvyPUJ5iLgHWPMMWPMemANrr8/R/8NGmO2G2PmW9sHgRW4lthMi9+jdAvogdY3jW6l1fRngC9FZJ61VitAC2PMdmt7B9DC2q7J1y3Sa1ITr9UtVrrgJXcqAb0+iEg+cCowhzT5PUq3gK4qDTHG9AHOB24WkWHeB43re5/2SfWi1ySg/wCdgd7AduCfya1OahCResAE4A/GmGLvY6n8e5RuAd3O+qY1gjFmq/XvLuAjXF+Fd7pTKda/u6ziNfm6RXpNatS1MsbsNMaUG2MqgOdx/R5BDb4+IpKNK5i/aYz50NqdFr9H6RbQ7axv6ngiUldE6ru3gfOApfiu7Xot8Im1PRG4xrojPxA44PX10ekivSZfAOeJSGMr/XCetc+R/O6l/AzX7xG4rs9lIpIrIh2BrsBcHP43KCKCa0nNFcaYJ7wOpcfvUbLvKkdxF3okrjvPa4F7k12fJF2DTrh6FywClrmvA9AUmAasBqYCTaz9AjxjXbMlQEGy30OcrsvbuNIGpbhyltdHc02AX+O6CbgGuC7Z7yvO1+d16/0vxhWcWnmVv9e6Pj8C53vtd+zfIDAEVzplMbDQ+hmZLr9HOvRfKaUcIt1SLkoppYLQgK6UUg6hAV0ppRxCA7pSSjmEBnSllHIIDehKKeUQGtCVUsoh/h+f6pcr30RyGgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjSCeYlpcw9v"
      },
      "source": [
        "# Deliverable 2: Explore NLP articles\n",
        "Now that you have your CNN trained, let's go ahead and make predictions for all of the 7,188 abstracts in our full dataset of NLP papers published between 2013-2020. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X55A-oFlaSaE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ebfff99-86d3-4eaf-bee1-5b7a2501cdd1"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/dbamman/nlp21/main/HW3/acl.all.tsv"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-10 21:09:57--  https://raw.githubusercontent.com/dbamman/nlp21/main/HW3/acl.all.tsv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7388302 (7.0M) [text/plain]\n",
            "Saving to: ‘acl.all.tsv’\n",
            "\n",
            "\racl.all.tsv           0%[                    ]       0  --.-KB/s               \racl.all.tsv         100%[===================>]   7.05M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2021-02-10 21:09:57 (112 MB/s) - ‘acl.all.tsv’ saved [7388302/7388302]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yC-1-sXdOn2g"
      },
      "source": [
        "def read_prediction_data(filename, vocab):\n",
        "    \"\"\"\n",
        "    :param filename: the name of the file\n",
        "    :return: list of tuple ([word index list], label)\n",
        "    as input for the forward and backward function\n",
        "    \"\"\"    \n",
        "    data = []\n",
        "    data_dates = []\n",
        "    file = open(filename)\n",
        "    for line in file:\n",
        "        cols = line.split(\"\\t\")\n",
        "        idd = cols[0]\n",
        "        year = int(cols[1])\n",
        "        title = cols[2]\n",
        "        abstract = cols[3]\n",
        "        w_int = []\n",
        "        for w in nltk.word_tokenize(title.lower()):\n",
        "            # skip the unknown words\n",
        "            if w in vocab:\n",
        "                w_int.append(vocab[w])\n",
        "            else:\n",
        "                w_int.append(UNKNOWN_INDEX)\n",
        "        w_int.append(SEP_INDEX)\n",
        "        w_int.append(SEP_INDEX)\n",
        "        for w in nltk.word_tokenize(abstract.lower()):\n",
        "            # skip the unknown words\n",
        "            if w in vocab:\n",
        "                w_int.append(vocab[w])\n",
        "            else:\n",
        "                w_int.append(UNKNOWN_INDEX)\n",
        "        data_lens.append(len(w_int))\n",
        "        if len(w_int) < 549:\n",
        "            w_int.extend([PAD_INDEX] * (549 - len(w_int)))\n",
        "        if len(w_int) < 550:\n",
        "          data.append((w_int))\n",
        "          data_dates.append(year)\n",
        "    file.close()\n",
        "    return data, data_dates"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btuKqE8LN6yS"
      },
      "source": [
        "predictFile=\"acl.all.tsv\"\n",
        "cnn_test_x, cnn_test_dates = read_prediction_data(predictFile, cnn_vocab)\n",
        "cnn_predictX, cnn_predictDates=get_batches(cnn_test_x, cnn_test_dates, torch.LongTensor, batch_size=256)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRa093KsPUYH"
      },
      "source": [
        "reverse_labels={labels[k]:k for k in labels}"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzNnW1HHdhFO"
      },
      "source": [
        "Now let's make predictions on all of that data with your trained `cnnmodel`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqpEWS69Oi8i"
      },
      "source": [
        "with torch.no_grad():\n",
        "\n",
        "  all_dates=[]\n",
        "  all_preds=[]\n",
        "  for x, y in zip(cnn_predictX, cnn_predictDates):\n",
        "    y_preds=cnnmodel.forward(x)\n",
        "    for idx, y_pred in enumerate(y_preds):\n",
        "        prediction=int(torch.argmax(y_pred))\n",
        "        all_dates.append(int(y[idx]))\n",
        "        all_preds.append(prediction)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvabtt6XdLnl"
      },
      "source": [
        "What are the most frequent categories among our predictions?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qvbk-FBnO_aD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "825a67a2-4df6-4ce9-ccd8-d8a37cb8d901"
      },
      "source": [
        "from collections import Counter\n",
        "cat_counts=Counter()\n",
        "for val in all_preds:\n",
        "  cat_counts[val]+=1\n",
        "\n",
        "for k,v in cat_counts.most_common():\n",
        "  print(v, reverse_labels[k])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "723 MT\n",
            "567 MULTILING\n",
            "500 SENTSEM\n",
            "500 APPLICATIONS\n",
            "496 QA\n",
            "489 IE\n",
            "477 DIALOGUE\n",
            "421 MLCLASS\n",
            "392 RESOURCES\n",
            "375 GENERATION\n",
            "356 SA\n",
            "322 MLLM\n",
            "250 SUMM\n",
            "247 LEXSEM\n",
            "237 INTERPRET\n",
            "217 GROUNDING\n",
            "136 SYNTAX\n",
            "99 ETHICS\n",
            "98 CSSCA\n",
            "91 DISCOURSE\n",
            "60 GREEN\n",
            "44 LING\n",
            "41 PHON\n",
            "25 SPEECH\n",
            "18 IR\n",
            "5 OTHER\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryVHtoQXdPFs"
      },
      "source": [
        "Now let's plot the frequency with which any given category appears over time by aggregating those predictions by the year in which the corresponding papers were published."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRGk370CPxXx"
      },
      "source": [
        "minYear=min(all_dates)\n",
        "maxYear=max(all_dates)\n",
        "counts=np.zeros((maxYear-minYear+1, len(labels)))\n",
        "for year, pred in zip(all_dates, all_preds):\n",
        "  counts[year-minYear][pred]+=1\n",
        "counts=counts/np.sum(counts,axis=1)[:, np.newaxis]"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V14d_5zxQZRC"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_category(cats, labels):\n",
        "  for cat in cats:\n",
        "    data=[]\n",
        "    for idx, val in enumerate(counts[:,labels[cat]]):\n",
        "      data.append(val)\n",
        "    plt.plot(range(2013,2021), data)\n",
        "  plt.legend(cats)\n",
        "  plt.show()\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GaSa5V0Qx-F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "52c8c1e9-66ba-4367-a19c-16b4bc58f3b9"
      },
      "source": [
        "plot_category([\"MT\", \"SA\", \"GENERATION\", \"ETHICS\"], labels)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAW6FujgeUOb"
      },
      "source": [
        "Should we trust these results as reflecting trends in the attention the ACL community gives to these topics?  Think about the potential biases that might exist in this method and the results, especially given your experience in creating this dataset.  Explore this model and data with whatever methods you think would help your argument -- e.g., try plotting a confusion matrix over the development data to see which classes are being confused, examine the data points that have the highest confidence wrong predictions, etc.).  How would you go about interrogating this method to know whether to trust these findings?  Submit your <200 word answer to this question as a PDF on gradescope.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Yp__mm6xznT"
      },
      "source": [
        "# finding predicted vs. true labels + confidence of incorrect predictions\n",
        "import pandas as pd\n",
        "\n",
        "total_preds = []\n",
        "\n",
        "for z, x in enumerate(cnn_devX):\n",
        "  y_preds = cnnmodel.forward(x)\n",
        "  preds = []\n",
        "  for y in y_preds:\n",
        "    y = torch.nn.functional.softmax(y, dim = 0)\n",
        "    preds.append(int(torch.argmax(y)))\n",
        "  total_preds.append(torch.tensor(preds))"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsTdLfaRx4ap"
      },
      "source": [
        "# flatten actual values from list of tensors to list\n",
        "\n",
        "lst1 = []\n",
        "\n",
        "for i in range(len(total_preds)):\n",
        "  lst1.append(total_preds[i].tolist())\n",
        "\n",
        "actual_output = []\n",
        "\n",
        "for i in range(len(lst1)):\n",
        "  for j in range(len(lst1[i])):\n",
        "    actual_output.append(lst1[i][j])\n",
        "\n",
        "actual_names = []\n",
        "for i in range(len(actual_output)):\n",
        "  for key in labels:\n",
        "    if int(labels[key]) == actual_output[i]:\n",
        "      actual_names.append(key)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1DqZfVR4O22"
      },
      "source": [
        "# flatten true values from list of tensors to list\n",
        "\n",
        "lst2 = []\n",
        "\n",
        "for i in range(len(cnn_devY)):\n",
        "  lst2.append(cnn_devY[i].tolist())\n",
        "\n",
        "expected_output = []\n",
        "\n",
        "for i in range(len(lst2)):\n",
        "  for j in range(len(lst2[i])):\n",
        "    expected_output.append(lst2[i][j])\n",
        "\n",
        "expected_names = []\n",
        "for i in range(len(expected_output)):\n",
        "  for key in labels:\n",
        "    if int(labels[key]) == expected_output[i]:\n",
        "      expected_names.append(key)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gn6IVxwfvOB_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 875
        },
        "outputId": "6f278dd7-4be0-4fae-b810-d97001c95928"
      },
      "source": [
        "y_actual = pd.Series(actual_names, name = 'Actual')\n",
        "y_predicted = pd.Series(expected_names, name = 'Predicted')\n",
        "df_confusion = pd.crosstab(y_predicted, y_actual).apply(lambda r: r/r.sum(), axis=1)\n",
        "df_confusion"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Actual</th>\n",
              "      <th>APPLICATIONS</th>\n",
              "      <th>CSSCA</th>\n",
              "      <th>DIALOGUE</th>\n",
              "      <th>DISCOURSE</th>\n",
              "      <th>ETHICS</th>\n",
              "      <th>GENERATION</th>\n",
              "      <th>GREEN</th>\n",
              "      <th>GROUNDING</th>\n",
              "      <th>IE</th>\n",
              "      <th>INTERPRET</th>\n",
              "      <th>LEXSEM</th>\n",
              "      <th>LING</th>\n",
              "      <th>MLCLASS</th>\n",
              "      <th>MLLM</th>\n",
              "      <th>MT</th>\n",
              "      <th>MULTILING</th>\n",
              "      <th>PHON</th>\n",
              "      <th>QA</th>\n",
              "      <th>RESOURCES</th>\n",
              "      <th>SA</th>\n",
              "      <th>SENTSEM</th>\n",
              "      <th>SUMM</th>\n",
              "      <th>SYNTAX</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Predicted</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>APPLICATIONS</th>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0625</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CSSCA</th>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DIALOGUE</th>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.866667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DISCOURSE</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ETHICS</th>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GENERATION</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GREEN</th>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GROUNDING</th>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.153846</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.307692</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.076923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>IE</th>\n",
              "      <td>0.080000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.080000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.080000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.040000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.080000</td>\n",
              "      <td>0.040000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>INTERPRET</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.142857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>IR</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LEXSEM</th>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.153846</td>\n",
              "      <td>0.153846</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.384615</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LING</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MLCLASS</th>\n",
              "      <td>0.031250</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.031250</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>0.031250</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>0.031250</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>0.031250</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>0.031250</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.062500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MLLM</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MT</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MULTILING</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.882353</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PHON</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>QA</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RESOURCES</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.083333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SA</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SENTSEM</th>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.350000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SPEECH</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SUMM</th>\n",
              "      <td>0.040000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.040000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.040000</td>\n",
              "      <td>0.040000</td>\n",
              "      <td>0.040000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.040000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.040000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.080000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.080000</td>\n",
              "      <td>0.5600</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SYNTAX</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.250000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Actual        APPLICATIONS     CSSCA  DIALOGUE  ...   SENTSEM    SUMM    SYNTAX\n",
              "Predicted                                       ...                            \n",
              "APPLICATIONS      0.375000  0.062500  0.000000  ...  0.000000  0.0625  0.000000\n",
              "CSSCA             0.333333  0.166667  0.000000  ...  0.000000  0.0000  0.000000\n",
              "DIALOGUE          0.066667  0.000000  0.866667  ...  0.066667  0.0000  0.000000\n",
              "DISCOURSE         0.000000  0.000000  0.000000  ...  0.000000  0.0000  0.000000\n",
              "ETHICS            0.090909  0.000000  0.000000  ...  0.000000  0.0000  0.000000\n",
              "GENERATION        0.000000  0.000000  0.111111  ...  0.111111  0.0000  0.000000\n",
              "GREEN             0.100000  0.000000  0.100000  ...  0.200000  0.0000  0.000000\n",
              "GROUNDING         0.076923  0.000000  0.153846  ...  0.000000  0.0000  0.076923\n",
              "IE                0.080000  0.000000  0.000000  ...  0.000000  0.0000  0.000000\n",
              "INTERPRET         0.000000  0.000000  0.000000  ...  0.142857  0.0000  0.142857\n",
              "IR                0.000000  0.000000  0.000000  ...  0.000000  0.0000  0.000000\n",
              "LEXSEM            0.076923  0.000000  0.000000  ...  0.384615  0.0000  0.000000\n",
              "LING              0.000000  0.000000  0.200000  ...  0.200000  0.0000  0.000000\n",
              "MLCLASS           0.031250  0.000000  0.000000  ...  0.031250  0.0000  0.062500\n",
              "MLLM              0.000000  0.000000  0.000000  ...  0.100000  0.0000  0.000000\n",
              "MT                0.000000  0.000000  0.000000  ...  0.000000  0.0000  0.000000\n",
              "MULTILING         0.000000  0.000000  0.000000  ...  0.058824  0.0000  0.000000\n",
              "PHON              0.000000  0.000000  0.000000  ...  0.250000  0.0000  0.000000\n",
              "QA                0.000000  0.045455  0.045455  ...  0.000000  0.0000  0.000000\n",
              "RESOURCES         0.000000  0.000000  0.083333  ...  0.000000  0.0000  0.083333\n",
              "SA                0.000000  0.071429  0.000000  ...  0.000000  0.0000  0.000000\n",
              "SENTSEM           0.050000  0.000000  0.000000  ...  0.350000  0.0000  0.000000\n",
              "SPEECH            0.000000  0.000000  1.000000  ...  0.000000  0.0000  0.000000\n",
              "SUMM              0.040000  0.000000  0.000000  ...  0.080000  0.5600  0.000000\n",
              "SYNTAX            0.000000  0.000000  0.000000  ...  0.000000  0.0000  0.250000\n",
              "\n",
              "[25 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1_4iHpb9q9M"
      },
      "source": [
        ""
      ],
      "execution_count": 40,
      "outputs": []
    }
  ]
}